{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 10 30.0\n",
      "\tgrad:  1.0 2.0 2.0\n",
      "\tgrad:  2.0 4.0 10.0\n",
      "\tgrad:  3.0 6.0 28.0\n",
      "\tgrad:  4.0 8.0 60.0\n",
      "\tgrad:  5.0 10.0 110.0\n",
      "\tgrad:  6.0 12.0 182.0\n",
      "\tgrad:  7.0 14.0 280.0\n",
      "\tgrad:  8.0 16.0 408.0\n",
      "progress: 0 w= 2.49 loss= 64.0\n",
      "\tgrad:  1.0 2.0 0.9800000000000004\n",
      "\tgrad:  2.0 4.0 4.900000000000002\n",
      "\tgrad:  3.0 6.0 13.720000000000006\n",
      "\tgrad:  4.0 8.0 29.400000000000013\n",
      "\tgrad:  5.0 10.0 53.90000000000002\n",
      "\tgrad:  6.0 12.0 89.18000000000004\n",
      "\tgrad:  7.0 14.0 137.20000000000005\n",
      "\tgrad:  8.0 16.0 199.92000000000007\n",
      "progress: 1 w= 2.2401 loss= 15.366400000000013\n",
      "\tgrad:  1.0 2.0 0.48019999999999996\n",
      "\tgrad:  2.0 4.0 2.401\n",
      "\tgrad:  3.0 6.0 6.722799999999999\n",
      "\tgrad:  4.0 8.0 14.405999999999999\n",
      "\tgrad:  5.0 10.0 26.410999999999998\n",
      "\tgrad:  6.0 12.0 43.6982\n",
      "\tgrad:  7.0 14.0 67.228\n",
      "\tgrad:  8.0 16.0 97.96079999999999\n",
      "progress: 2 w= 2.117649 loss= 3.6894726399999995\n",
      "\tgrad:  1.0 2.0 0.23529800000000023\n",
      "\tgrad:  2.0 4.0 1.1764900000000011\n",
      "\tgrad:  3.0 6.0 3.294172000000003\n",
      "\tgrad:  4.0 8.0 7.058940000000007\n",
      "\tgrad:  5.0 10.0 12.941390000000013\n",
      "\tgrad:  6.0 12.0 21.41211800000002\n",
      "\tgrad:  7.0 14.0 32.94172000000003\n",
      "\tgrad:  8.0 16.0 48.00079200000005\n",
      "progress: 3 w= 2.05764801 loss= 0.8858423808640017\n",
      "\tgrad:  1.0 2.0 0.11529601999999972\n",
      "\tgrad:  2.0 4.0 0.5764800999999986\n",
      "\tgrad:  3.0 6.0 1.6141442799999988\n",
      "\tgrad:  4.0 8.0 3.4588805999999943\n",
      "\tgrad:  5.0 10.0 6.341281099999983\n",
      "\tgrad:  6.0 12.0 10.491937819999983\n",
      "\tgrad:  7.0 14.0 16.141442799999975\n",
      "\tgrad:  8.0 16.0 23.520388079999957\n",
      "progress: 4 w= 2.0282475249 loss= 0.21269075564544537\n",
      "\tgrad:  1.0 2.0 0.05649504979999964\n",
      "\tgrad:  2.0 4.0 0.2824752489999982\n",
      "\tgrad:  3.0 6.0 0.7909306971999976\n",
      "\tgrad:  4.0 8.0 1.694851493999992\n",
      "\tgrad:  5.0 10.0 3.1072277389999785\n",
      "\tgrad:  6.0 12.0 5.141049531799976\n",
      "\tgrad:  7.0 14.0 7.909306971999965\n",
      "\tgrad:  8.0 16.0 11.524990159199941\n",
      "progress: 5 w= 2.013841287201 loss= 0.05106705043047103\n",
      "\tgrad:  1.0 2.0 0.02768257440200017\n",
      "\tgrad:  2.0 4.0 0.13841287201000085\n",
      "\tgrad:  3.0 6.0 0.3875560416280024\n",
      "\tgrad:  4.0 8.0 0.8304772320600051\n",
      "\tgrad:  5.0 10.0 1.5225415921100094\n",
      "\tgrad:  6.0 12.0 2.5191142705820155\n",
      "\tgrad:  7.0 14.0 3.875560416280024\n",
      "\tgrad:  8.0 16.0 5.647245178008035\n",
      "progress: 6 w= 2.00678223072849 loss= 0.012261198808356402\n",
      "\tgrad:  1.0 2.0 0.01356446145697987\n",
      "\tgrad:  2.0 4.0 0.06782230728489935\n",
      "\tgrad:  3.0 6.0 0.1899024603977182\n",
      "\tgrad:  4.0 8.0 0.4069338437093961\n",
      "\tgrad:  5.0 10.0 0.7460453801338929\n",
      "\tgrad:  6.0 12.0 1.2343659925851682\n",
      "\tgrad:  7.0 14.0 1.8990246039771819\n",
      "\tgrad:  8.0 16.0 2.7671501372238936\n",
      "progress: 7 w= 2.00332329305696 loss= 0.0029439138338862797\n",
      "\tgrad:  1.0 2.0 0.006646586113919994\n",
      "\tgrad:  2.0 4.0 0.03323293056959997\n",
      "\tgrad:  3.0 6.0 0.09305220559487992\n",
      "\tgrad:  4.0 8.0 0.19939758341759983\n",
      "\tgrad:  5.0 10.0 0.3655622362655997\n",
      "\tgrad:  6.0 12.0 0.6048393363667195\n",
      "\tgrad:  7.0 14.0 0.9305220559487992\n",
      "\tgrad:  8.0 16.0 1.3559035672396789\n",
      "progress: 8 w= 2.0016284135979103 loss= 0.0007068337115160655\n",
      "\tgrad:  1.0 2.0 0.003256827195820655\n",
      "\tgrad:  2.0 4.0 0.016284135979103276\n",
      "\tgrad:  3.0 6.0 0.04559558074149184\n",
      "\tgrad:  4.0 8.0 0.09770481587462232\n",
      "\tgrad:  5.0 10.0 0.17912549577013426\n",
      "\tgrad:  6.0 12.0 0.2963712748196885\n",
      "\tgrad:  7.0 14.0 0.4559558074149068\n",
      "\tgrad:  8.0 16.0 0.6643927479474288\n",
      "progress: 9 w= 2.000797922662976 loss= 0.00016971077413499252\n",
      "\tgrad:  1.0 2.0 0.0015958453259523608\n",
      "\tgrad:  2.0 4.0 0.007979226629761804\n",
      "\tgrad:  3.0 6.0 0.022341834563335716\n",
      "\tgrad:  4.0 8.0 0.04787535977857349\n",
      "\tgrad:  5.0 10.0 0.08777149292737807\n",
      "\tgrad:  6.0 12.0 0.14522192466167372\n",
      "\tgrad:  7.0 14.0 0.22341834563334562\n",
      "\tgrad:  8.0 16.0 0.3255524464942967\n",
      "progress: 10 w= 2.000390982104858 loss= 4.074755686982395e-05\n",
      "\tgrad:  1.0 2.0 0.0007819642097164348\n",
      "\tgrad:  2.0 4.0 0.003909821048582174\n",
      "\tgrad:  3.0 6.0 0.010947498936030087\n",
      "\tgrad:  4.0 8.0 0.023458926291493043\n",
      "\tgrad:  5.0 10.0 0.04300803153439503\n",
      "\tgrad:  6.0 12.0 0.07115874308418668\n",
      "\tgrad:  7.0 14.0 0.10947498936030442\n",
      "\tgrad:  8.0 16.0 0.15952069878215624\n",
      "progress: 11 w= 2.0001915812313804 loss= 9.783488404439173e-06\n",
      "\tgrad:  1.0 2.0 0.0003831624627608221\n",
      "\tgrad:  2.0 4.0 0.0019158123138041105\n",
      "\tgrad:  3.0 6.0 0.0053642744786515095\n",
      "\tgrad:  4.0 8.0 0.011494873882824663\n",
      "\tgrad:  5.0 10.0 0.021073935451845216\n",
      "\tgrad:  6.0 12.0 0.03486778411123481\n",
      "\tgrad:  7.0 14.0 0.053642744786515095\n",
      "\tgrad:  8.0 16.0 0.07816514240320771\n",
      "progress: 12 w= 2.0000938748033765 loss= 2.349015565903014e-06\n",
      "\tgrad:  1.0 2.0 0.00018774960675305152\n",
      "\tgrad:  2.0 4.0 0.0009387480337652576\n",
      "\tgrad:  3.0 6.0 0.002628494494545386\n",
      "\tgrad:  4.0 8.0 0.00563248820259421\n",
      "\tgrad:  5.0 10.0 0.010326228371416057\n",
      "\tgrad:  6.0 12.0 0.01708521421453657\n",
      "\tgrad:  7.0 14.0 0.026284944945442312\n",
      "\tgrad:  8.0 16.0 0.03830091977763761\n",
      "progress: 13 w= 2.0000459986536545 loss= 5.639986373748078e-07\n",
      "\tgrad:  1.0 2.0 9.199730730902189e-05\n",
      "\tgrad:  2.0 4.0 0.00045998653654510946\n",
      "\tgrad:  3.0 6.0 0.001287962302328971\n",
      "\tgrad:  4.0 8.0 0.0027599192192733213\n",
      "\tgrad:  5.0 10.0 0.005059851901994428\n",
      "\tgrad:  6.0 12.0 0.008371754965129874\n",
      "\tgrad:  7.0 14.0 0.012879623023278164\n",
      "\tgrad:  8.0 16.0 0.018767450691055565\n",
      "progress: 14 w= 2.0000225393402906 loss= 1.354160728337698e-07\n",
      "\tgrad:  1.0 2.0 4.507868058123421e-05\n",
      "\tgrad:  2.0 4.0 0.00022539340290617105\n",
      "\tgrad:  3.0 6.0 0.0006311015281346144\n",
      "\tgrad:  4.0 8.0 0.0013523604174343618\n",
      "\tgrad:  5.0 10.0 0.002479327431969658\n",
      "\tgrad:  6.0 12.0 0.004102159932883431\n",
      "\tgrad:  7.0 14.0 0.00631101528135769\n",
      "\tgrad:  8.0 16.0 0.00919605083855668\n",
      "progress: 15 w= 2.0000110442767425 loss= 3.251339908711908e-08\n",
      "\tgrad:  1.0 2.0 2.2088553484955753e-05\n",
      "\tgrad:  2.0 4.0 0.00011044276742477876\n",
      "\tgrad:  3.0 6.0 0.000309239748786716\n",
      "\tgrad:  4.0 8.0 0.0006626566045460081\n",
      "\tgrad:  5.0 10.0 0.0012148704416743428\n",
      "\tgrad:  6.0 12.0 0.0020100583671220917\n",
      "\tgrad:  7.0 14.0 0.0030923974878787064\n",
      "\tgrad:  8.0 16.0 0.004506064910915875\n",
      "progress: 16 w= 2.0000054116956036 loss= 7.806467120924016e-09\n",
      "\tgrad:  1.0 2.0 1.082339120728193e-05\n",
      "\tgrad:  2.0 4.0 5.411695603640965e-05\n",
      "\tgrad:  3.0 6.0 0.000151527476901947\n",
      "\tgrad:  4.0 8.0 0.0003247017362184579\n",
      "\tgrad:  5.0 10.0 0.0005952865164005061\n",
      "\tgrad:  6.0 12.0 0.0009849285998626556\n",
      "\tgrad:  7.0 14.0 0.0015152747690194701\n",
      "\tgrad:  8.0 16.0 0.0022079718062855136\n",
      "progress: 17 w= 2.0000026517308456 loss= 1.8743327556138847e-09\n",
      "\tgrad:  1.0 2.0 5.30346169114182e-06\n",
      "\tgrad:  2.0 4.0 2.65173084557091e-05\n",
      "\tgrad:  3.0 6.0 7.424846367598548e-05\n",
      "\tgrad:  4.0 8.0 0.0001591038507342546\n",
      "\tgrad:  5.0 10.0 0.0002916903930128001\n",
      "\tgrad:  6.0 12.0 0.0004826150138939056\n",
      "\tgrad:  7.0 14.0 0.0007424846367598548\n",
      "\tgrad:  8.0 16.0 0.0010819061849929312\n",
      "progress: 18 w= 2.0000012993481144 loss= 4.5002729455054163e-10\n",
      "\tgrad:  1.0 2.0 2.5986962288726545e-06\n",
      "\tgrad:  2.0 4.0 1.2993481144363273e-05\n",
      "\tgrad:  3.0 6.0 3.638174720421716e-05\n",
      "\tgrad:  4.0 8.0 7.796088686617964e-05\n",
      "\tgrad:  5.0 10.0 0.0001429282925791142\n",
      "\tgrad:  6.0 12.0 0.00023648135681852978\n",
      "\tgrad:  7.0 14.0 0.00036381747204572434\n",
      "\tgrad:  8.0 16.0 0.0005301340306935742\n",
      "progress: 19 w= 2.0000006366805763 loss= 1.080515534393113e-10\n",
      "\tgrad:  1.0 2.0 1.2733611525206356e-06\n",
      "\tgrad:  2.0 4.0 6.366805762603178e-06\n",
      "\tgrad:  3.0 6.0 1.7827056132624364e-05\n",
      "\tgrad:  4.0 8.0 3.8200834572954534e-05\n",
      "\tgrad:  5.0 10.0 7.003486339041132e-05\n",
      "\tgrad:  6.0 12.0 0.00011587586487049606\n",
      "\tgrad:  7.0 14.0 0.00017827056133778996\n",
      "\tgrad:  8.0 16.0 0.00025976567509911064\n",
      "progress: 20 w= 2.0000003119734826 loss= 2.5943177995978903e-11\n",
      "\tgrad:  1.0 2.0 6.23946965205846e-07\n",
      "\tgrad:  2.0 4.0 3.11973482602923e-06\n",
      "\tgrad:  3.0 6.0 8.735257512881844e-06\n",
      "\tgrad:  4.0 8.0 1.871840895617538e-05\n",
      "\tgrad:  5.0 10.0 3.4317083095203316e-05\n",
      "\tgrad:  6.0 12.0 5.677917384261377e-05\n",
      "\tgrad:  7.0 14.0 8.735257512526573e-05\n",
      "\tgrad:  8.0 16.0 0.00012728518089843988\n",
      "progress: 21 w= 2.0000001528670066 loss= 6.228957046233364e-12\n",
      "\tgrad:  1.0 2.0 3.057340132173181e-07\n",
      "\tgrad:  2.0 4.0 1.5286700660865904e-06\n",
      "\tgrad:  3.0 6.0 4.280276187706988e-06\n",
      "\tgrad:  4.0 8.0 9.172020399184078e-06\n",
      "\tgrad:  5.0 10.0 1.6815370725176138e-05\n",
      "\tgrad:  6.0 12.0 2.782179521165773e-05\n",
      "\tgrad:  7.0 14.0 4.2802761865523564e-05\n",
      "\tgrad:  8.0 16.0 6.236973871143192e-05\n",
      "progress: 22 w= 2.000000074904833 loss= 1.4955725894074756e-12\n",
      "\tgrad:  1.0 2.0 1.498096660057513e-07\n",
      "\tgrad:  2.0 4.0 7.490483300287565e-07\n",
      "\tgrad:  3.0 6.0 2.0973353267450534e-06\n",
      "\tgrad:  4.0 8.0 4.494289982837074e-06\n",
      "\tgrad:  5.0 10.0 8.239531628539964e-06\n",
      "\tgrad:  6.0 12.0 1.3632679615405152e-05\n",
      "\tgrad:  7.0 14.0 2.0973353255904215e-05\n",
      "\tgrad:  8.0 16.0 3.05611718802723e-05\n",
      "progress: 23 w= 2.0000000367033683 loss= 3.590869764600761e-13\n",
      "\tgrad:  1.0 2.0 7.340673668920772e-08\n",
      "\tgrad:  2.0 4.0 3.670336834460386e-07\n",
      "\tgrad:  3.0 6.0 1.027694313648908e-06\n",
      "\tgrad:  4.0 8.0 2.2022021006762316e-06\n",
      "\tgrad:  5.0 10.0 4.037370526788209e-06\n",
      "\tgrad:  6.0 12.0 6.680013047599687e-06\n",
      "\tgrad:  7.0 14.0 1.0276943132936367e-05\n",
      "\tgrad:  8.0 16.0 1.4974974281045661e-05\n",
      "progress: 24 w= 2.0000000179846507 loss= 8.62167838617388e-14\n",
      "\tgrad:  1.0 2.0 3.596930131521958e-08\n",
      "\tgrad:  2.0 4.0 1.798465065760979e-07\n",
      "\tgrad:  3.0 6.0 5.035702210776094e-07\n",
      "\tgrad:  4.0 8.0 1.0790790421211227e-06\n",
      "\tgrad:  5.0 10.0 1.97831157056072e-06\n",
      "\tgrad:  6.0 12.0 3.273206428566766e-06\n",
      "\tgrad:  7.0 14.0 5.035702199229775e-06\n",
      "\tgrad:  8.0 16.0 7.337737483403828e-06\n",
      "progress: 25 w= 2.0000000088124787 loss= 2.0700650193680914e-14\n",
      "\tgrad:  1.0 2.0 1.7624957493467264e-08\n",
      "\tgrad:  2.0 4.0 8.812478746733632e-08\n",
      "\tgrad:  3.0 6.0 2.467494049085417e-07\n",
      "\tgrad:  4.0 8.0 5.287487248040179e-07\n",
      "\tgrad:  5.0 10.0 9.693726532589153e-07\n",
      "\tgrad:  6.0 12.0 1.6038711230237368e-06\n",
      "\tgrad:  7.0 14.0 2.4674940526381306e-06\n",
      "\tgrad:  8.0 16.0 3.5954913322200355e-06\n",
      "progress: 26 w= 2.0000000043181148 loss= 4.970226026344446e-15\n",
      "\tgrad:  1.0 2.0 8.636229509306759e-09\n",
      "\tgrad:  2.0 4.0 4.3181147546533794e-08\n",
      "\tgrad:  3.0 6.0 1.2090721313029462e-07\n",
      "\tgrad:  4.0 8.0 2.5908688527920276e-07\n",
      "\tgrad:  5.0 10.0 4.7499261413008753e-07\n",
      "\tgrad:  6.0 12.0 7.858968764651308e-07\n",
      "\tgrad:  7.0 14.0 1.20907213485566e-06\n",
      "\tgrad:  8.0 16.0 1.7617908234512925e-06\n",
      "progress: 27 w= 2.0000000021158764 loss= 1.1933513621987337e-15\n",
      "\tgrad:  1.0 2.0 4.231752726013838e-09\n",
      "\tgrad:  2.0 4.0 2.115876363006919e-08\n",
      "\tgrad:  3.0 6.0 5.924453816419373e-08\n",
      "\tgrad:  4.0 8.0 1.2695258178041513e-07\n",
      "\tgrad:  5.0 10.0 2.3274639104897688e-07\n",
      "\tgrad:  6.0 12.0 3.8508948918547503e-07\n",
      "\tgrad:  7.0 14.0 5.92445385194651e-07\n",
      "\tgrad:  8.0 16.0 8.632775596595366e-07\n",
      "progress: 28 w= 2.0000000010367796 loss= 2.8652369814600874e-16\n",
      "\tgrad:  1.0 2.0 2.0735591022003064e-09\n",
      "\tgrad:  2.0 4.0 1.0367795511001532e-08\n",
      "\tgrad:  3.0 6.0 2.902982743080429e-08\n",
      "\tgrad:  4.0 8.0 6.220677306600919e-08\n",
      "\tgrad:  5.0 10.0 1.1404575062101685e-07\n",
      "\tgrad:  6.0 12.0 1.8869387830022788e-07\n",
      "\tgrad:  7.0 14.0 2.902982743080429e-07\n",
      "\tgrad:  8.0 16.0 4.230060568488625e-07\n",
      "progress: 29 w= 2.000000000508022 loss= 6.879435760508385e-17\n",
      "\tgrad:  1.0 2.0 1.016044137713834e-09\n",
      "\tgrad:  2.0 4.0 5.08022068856917e-09\n",
      "\tgrad:  3.0 6.0 1.4224617927993677e-08\n",
      "\tgrad:  4.0 8.0 3.048132413141502e-08\n",
      "\tgrad:  5.0 10.0 5.5882427574260873e-08\n",
      "\tgrad:  6.0 12.0 9.24600165319589e-08\n",
      "\tgrad:  7.0 14.0 1.4224617927993677e-07\n",
      "\tgrad:  8.0 16.0 2.0727300409362215e-07\n",
      "progress: 30 w= 2.0000000002489307 loss= 1.6517531036522378e-17\n",
      "\tgrad:  1.0 2.0 4.978613077355476e-10\n",
      "\tgrad:  2.0 4.0 2.489306538677738e-09\n",
      "\tgrad:  3.0 6.0 6.970058308297666e-09\n",
      "\tgrad:  4.0 8.0 1.4935839232066428e-08\n",
      "\tgrad:  5.0 10.0 2.7382380807239315e-08\n",
      "\tgrad:  6.0 12.0 4.530538788571903e-08\n",
      "\tgrad:  7.0 14.0 6.970057953026298e-08\n",
      "\tgrad:  8.0 16.0 1.0156370322533803e-07\n",
      "progress: 31 w= 2.000000000121976 loss= 3.965854107842394e-18\n",
      "\tgrad:  1.0 2.0 2.439524138253546e-10\n",
      "\tgrad:  2.0 4.0 1.219762069126773e-09\n",
      "\tgrad:  3.0 6.0 3.4153337935549644e-09\n",
      "\tgrad:  4.0 8.0 7.318572414760638e-09\n",
      "\tgrad:  5.0 10.0 1.3417373878610306e-08\n",
      "\tgrad:  6.0 12.0 2.219966077632307e-08\n",
      "\tgrad:  7.0 14.0 3.415334148826332e-08\n",
      "\tgrad:  8.0 16.0 4.9766295973086017e-08\n",
      "progress: 32 w= 2.000000000059768 loss= 9.52204483379473e-19\n",
      "\tgrad:  1.0 2.0 1.1953638079376105e-10\n",
      "\tgrad:  2.0 4.0 5.976819039688053e-10\n",
      "\tgrad:  3.0 6.0 1.6735093311126548e-09\n",
      "\tgrad:  4.0 8.0 3.5860914238128316e-09\n",
      "\tgrad:  5.0 10.0 6.574492061872661e-09\n",
      "\tgrad:  6.0 12.0 1.0877801770448059e-08\n",
      "\tgrad:  7.0 14.0 1.6735096863840226e-08\n",
      "\tgrad:  8.0 16.0 2.4385425234640934e-08\n",
      "progress: 33 w= 2.0000000000292864 loss= 2.2862314133233675e-19\n",
      "\tgrad:  1.0 2.0 5.857270224396416e-11\n",
      "\tgrad:  2.0 4.0 2.928635112198208e-10\n",
      "\tgrad:  3.0 6.0 8.200151668802391e-10\n",
      "\tgrad:  4.0 8.0 1.7571784027836657e-09\n",
      "\tgrad:  5.0 10.0 3.221500399774868e-09\n",
      "\tgrad:  6.0 12.0 5.3301070224165414e-09\n",
      "\tgrad:  7.0 14.0 8.200163215121847e-09\n",
      "\tgrad:  8.0 16.0 1.1948816158735553e-08\n",
      "progress: 34 w= 2.0000000000143503 loss= 5.489218317056134e-20\n",
      "\tgrad:  1.0 2.0 2.8700597454189847e-11\n",
      "\tgrad:  2.0 4.0 1.4350298727094923e-10\n",
      "\tgrad:  3.0 6.0 4.0180836435865785e-10\n",
      "\tgrad:  4.0 8.0 8.610179236256954e-10\n",
      "\tgrad:  5.0 10.0 1.5785239781962446e-09\n",
      "\tgrad:  6.0 12.0 2.611745486547079e-09\n",
      "\tgrad:  7.0 14.0 4.018087196300257e-09\n",
      "\tgrad:  8.0 16.0 5.8549254333684075e-09\n",
      "progress: 35 w= 2.0000000000070317 loss= 1.317958870763918e-20\n",
      "\tgrad:  1.0 2.0 1.4063417097531783e-11\n",
      "\tgrad:  2.0 4.0 7.031708548765891e-11\n",
      "\tgrad:  3.0 6.0 1.9688783936544496e-10\n",
      "\tgrad:  4.0 8.0 4.219025129259535e-10\n",
      "\tgrad:  5.0 10.0 7.734790585800511e-10\n",
      "\tgrad:  6.0 12.0 1.2797620740911952e-09\n",
      "\tgrad:  7.0 14.0 1.9688819463681284e-09\n",
      "\tgrad:  8.0 16.0 2.8689406406101625e-09\n",
      "progress: 36 w= 2.0000000000034457 loss= 3.1644752073463884e-21\n",
      "\tgrad:  1.0 2.0 6.891376358453272e-12\n",
      "\tgrad:  2.0 4.0 3.445688179226636e-11\n",
      "\tgrad:  3.0 6.0 9.64766044830867e-11\n",
      "\tgrad:  4.0 8.0 2.0673862621833905e-10\n",
      "\tgrad:  5.0 10.0 3.7902747607176934e-10\n",
      "\tgrad:  6.0 12.0 6.271063668350507e-10\n",
      "\tgrad:  7.0 14.0 9.647775911503231e-10\n",
      "\tgrad:  8.0 16.0 1.4058256780913325e-09\n",
      "progress: 37 w= 2.0000000000016884 loss= 7.598570898215788e-22\n",
      "\tgrad:  1.0 2.0 3.376854351699876e-12\n",
      "\tgrad:  2.0 4.0 1.688427175849938e-11\n",
      "\tgrad:  3.0 6.0 4.7275960923798266e-11\n",
      "\tgrad:  4.0 8.0 1.0130563055099628e-10\n",
      "\tgrad:  5.0 10.0 1.8571810755929619e-10\n",
      "\tgrad:  6.0 12.0 3.0728486422049173e-10\n",
      "\tgrad:  7.0 14.0 4.727631619516615e-10\n",
      "\tgrad:  8.0 16.0 6.888818404604535e-10\n",
      "progress: 38 w= 2.0000000000008273 loss= 1.8245032500151025e-22\n",
      "\tgrad:  1.0 2.0 1.6546763959013333e-12\n",
      "\tgrad:  2.0 4.0 8.273381979506667e-12\n",
      "\tgrad:  3.0 6.0 2.3162805007359566e-11\n",
      "\tgrad:  4.0 8.0 4.96376273417809e-11\n",
      "\tgrad:  5.0 10.0 9.100897813141273e-11\n",
      "\tgrad:  6.0 12.0 1.5056667024282433e-10\n",
      "\tgrad:  7.0 14.0 2.3163959639305176e-10\n",
      "\tgrad:  8.0 16.0 3.375388857307371e-10\n",
      "progress: 39 w= 2.0000000000004055 loss= 4.3807263602448415e-23\n",
      "\tgrad:  1.0 2.0 8.109068971862143e-13\n",
      "\tgrad:  2.0 4.0 4.054534485931072e-12\n",
      "\tgrad:  3.0 6.0 1.1355361095866101e-11\n",
      "\tgrad:  4.0 8.0 2.432987145084553e-11\n",
      "\tgrad:  5.0 10.0 4.459810298840239e-11\n",
      "\tgrad:  6.0 12.0 7.38014094281425e-11\n",
      "\tgrad:  7.0 14.0 1.1354206463920491e-10\n",
      "\tgrad:  8.0 16.0 1.6544010605912263e-10\n",
      "progress: 40 w= 2.0000000000001985 loss= 1.0521119934466777e-23\n",
      "\tgrad:  1.0 2.0 3.97015753605956e-13\n",
      "\tgrad:  2.0 4.0 1.98507876802978e-12\n",
      "\tgrad:  3.0 6.0 5.555556015224283e-12\n",
      "\tgrad:  4.0 8.0 1.1907808072919579e-11\n",
      "\tgrad:  5.0 10.0 2.183764280516698e-11\n",
      "\tgrad:  6.0 12.0 3.611955179394499e-11\n",
      "\tgrad:  7.0 14.0 5.5567106471698935e-11\n",
      "\tgrad:  8.0 16.0 8.097611470248012e-11\n",
      "progress: 41 w= 2.0000000000000973 loss= 2.5219441377808824e-24\n",
      "\tgrad:  1.0 2.0 1.9451107391432743e-13\n",
      "\tgrad:  2.0 4.0 9.725553695716371e-13\n",
      "\tgrad:  3.0 6.0 2.7204904995414836e-12\n",
      "\tgrad:  4.0 8.0 5.832667682170722e-12\n",
      "\tgrad:  5.0 10.0 1.0699885422127409e-11\n",
      "\tgrad:  6.0 12.0 1.7691625942006795e-11\n",
      "\tgrad:  7.0 14.0 2.7216451314870937e-11\n",
      "\tgrad:  8.0 16.0 3.966516004538789e-11\n",
      "progress: 42 w= 2.0000000000000475 loss= 6.053529260048792e-25\n",
      "\tgrad:  1.0 2.0 9.50350909079134e-14\n",
      "\tgrad:  2.0 4.0 4.75175454539567e-13\n",
      "\tgrad:  3.0 6.0 1.3278267374516872e-12\n",
      "\tgrad:  4.0 8.0 2.8483881919783016e-12\n",
      "\tgrad:  5.0 10.0 5.228706356774637e-12\n",
      "\tgrad:  6.0 12.0 8.639311488423118e-12\n",
      "\tgrad:  7.0 14.0 1.3289813693972974e-11\n",
      "\tgrad:  8.0 16.0 1.937205951207943e-11\n",
      "progress: 43 w= 2.000000000000023 loss= 1.4450669606200583e-25\n",
      "\tgrad:  1.0 2.0 4.618527782440651e-14\n",
      "\tgrad:  2.0 4.0 2.3092638912203256e-13\n",
      "\tgrad:  3.0 6.0 6.465938895416912e-13\n",
      "\tgrad:  4.0 8.0 1.3855583347321954e-12\n",
      "\tgrad:  5.0 10.0 2.540190280342358e-12\n",
      "\tgrad:  6.0 12.0 4.202860282020993e-12\n",
      "\tgrad:  7.0 14.0 6.465938895416912e-12\n",
      "\tgrad:  8.0 16.0 9.421796676178928e-12\n",
      "progress: 44 w= 2.000000000000011 loss= 3.4129278203481855e-26\n",
      "\tgrad:  1.0 2.0 2.220446049250313e-14\n",
      "\tgrad:  2.0 4.0 1.1102230246251565e-13\n",
      "\tgrad:  3.0 6.0 3.135269821541442e-13\n",
      "\tgrad:  4.0 8.0 6.687983500341943e-13\n",
      "\tgrad:  5.0 10.0 1.219468970248272e-12\n",
      "\tgrad:  6.0 12.0 2.029487689014786e-12\n",
      "\tgrad:  7.0 14.0 3.1237235020853404e-12\n",
      "\tgrad:  8.0 16.0 4.544808973605541e-12\n",
      "progress: 45 w= 2.0000000000000053 loss= 7.888609052210118e-27\n",
      "\tgrad:  1.0 2.0 1.0658141036401503e-14\n",
      "\tgrad:  2.0 4.0 5.3290705182007514e-14\n",
      "\tgrad:  3.0 6.0 1.4921397450962104e-13\n",
      "\tgrad:  4.0 8.0 3.197442310920451e-13\n",
      "\tgrad:  5.0 10.0 5.861977570020827e-13\n",
      "\tgrad:  6.0 12.0 9.698908343125368e-13\n",
      "\tgrad:  7.0 14.0 1.4921397450962104e-12\n",
      "\tgrad:  8.0 16.0 2.1742607714259066e-12\n",
      "progress: 46 w= 2.0000000000000027 loss= 1.8175355256292112e-27\n",
      "\tgrad:  1.0 2.0 5.329070518200751e-15\n",
      "\tgrad:  2.0 4.0 2.6645352591003757e-14\n",
      "\tgrad:  3.0 6.0 7.460698725481052e-14\n",
      "\tgrad:  4.0 8.0 1.5987211554602254e-13\n",
      "\tgrad:  5.0 10.0 3.019806626980426e-13\n",
      "\tgrad:  6.0 12.0 4.938272013532696e-13\n",
      "\tgrad:  7.0 14.0 7.425171588693047e-13\n",
      "\tgrad:  8.0 16.0 1.0835776720341528e-12\n",
      "progress: 47 w= 2.0000000000000013 loss= 4.543838814073028e-28\n",
      "\tgrad:  1.0 2.0 2.6645352591003757e-15\n",
      "\tgrad:  2.0 4.0 1.3322676295501878e-14\n",
      "\tgrad:  3.0 6.0 3.4638958368304884e-14\n",
      "\tgrad:  4.0 8.0 7.72715225139109e-14\n",
      "\tgrad:  5.0 10.0 1.4832579608992091e-13\n",
      "\tgrad:  6.0 12.0 2.3359092438113294e-13\n",
      "\tgrad:  7.0 14.0 3.5793590313915047e-13\n",
      "\tgrad:  8.0 16.0 5.284661597215745e-13\n",
      "progress: 48 w= 2.000000000000001 loss= 1.135959703518257e-28\n",
      "\tgrad:  1.0 2.0 1.7763568394002505e-15\n",
      "\tgrad:  2.0 4.0 8.881784197001252e-15\n",
      "\tgrad:  3.0 6.0 2.4868995751603507e-14\n",
      "\tgrad:  4.0 8.0 5.3290705182007514e-14\n",
      "\tgrad:  5.0 10.0 8.881784197001252e-14\n",
      "\tgrad:  6.0 12.0 1.5276668818842154e-13\n",
      "\tgrad:  7.0 14.0 2.5224267119483557e-13\n",
      "\tgrad:  8.0 16.0 3.659295089164516e-13\n",
      "progress: 49 w= 2.0000000000000004 loss= 5.048709793414476e-29\n",
      "\tgrad:  1.0 2.0 8.881784197001252e-16\n",
      "\tgrad:  2.0 4.0 4.440892098500626e-15\n",
      "\tgrad:  3.0 6.0 1.509903313490213e-14\n",
      "\tgrad:  4.0 8.0 2.930988785010413e-14\n",
      "\tgrad:  5.0 10.0 4.707345624410664e-14\n",
      "\tgrad:  6.0 12.0 8.970602038971265e-14\n",
      "\tgrad:  7.0 14.0 1.3944401189291966e-13\n",
      "\tgrad:  8.0 16.0 1.9628743075372768e-13\n",
      "progress: 50 w= 2.0 loss= 1.262177448353619e-29\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 51 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 52 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 53 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 54 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 55 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 56 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 57 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 58 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 59 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 60 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 61 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 62 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 63 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 64 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 65 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 66 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 67 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 68 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 69 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 70 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 71 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 72 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 73 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 74 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 75 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 76 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 77 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 78 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 79 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 80 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 81 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 82 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 83 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 84 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 85 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 86 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 87 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 88 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 89 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 90 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 91 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 92 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 93 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 94 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 95 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 96 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 97 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 98 w= 2.0 loss= 0.0\n",
      "\tgrad:  1.0 2.0 0.0\n",
      "\tgrad:  2.0 4.0 0.0\n",
      "\tgrad:  3.0 6.0 0.0\n",
      "\tgrad:  4.0 8.0 0.0\n",
      "\tgrad:  5.0 10.0 0.0\n",
      "\tgrad:  6.0 12.0 0.0\n",
      "\tgrad:  7.0 14.0 0.0\n",
      "\tgrad:  8.0 16.0 0.0\n",
      "progress: 99 w= 2.0 loss= 0.0\n",
      "predict (after training) 10 hours 20.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n",
    "y_data = [2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0]\n",
    "\n",
    "# y = w * x + b，目前把b省略，單純一個變數\n",
    "\n",
    "w = 3.0  # a random guess: random value, 1.0\n",
    "\n",
    "# our model for the forward pass\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "# Loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "# compute gradient\n",
    "def gradient(x, y):  # d_loss/d_w\n",
    "    return 2 * x * (x * w - y)\n",
    "\n",
    "# Before training\n",
    "print(\"predict (before training)\",  10, forward(10))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    grad = 0\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        gradi = gradient(x_val, y_val)\n",
    "        grad += gradi #把所有樣本的梯度相加起來\n",
    "        print(\"\\tgrad: \", x_val, y_val, grad)\n",
    "        l = loss(x_val, y_val)\n",
    "    w = w - 0.01 * grad/len(x_data) # sgd是把每一批的梯度相加除以總數，這邊用整體的梯度總和\n",
    "    print(\"progress:\", epoch, \"w=\", w, \"loss=\", l)\n",
    "\n",
    "# After training\n",
    "print(\"predict (after training)\",  \"10 hours\", forward(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variable gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "\n",
    "w1 = 1.0  # a random guess: random value, 1.0\n",
    "w2 = 1.0\n",
    "b = 1.0\n",
    "\n",
    "# our model for the forward pass\n",
    "def forward(x):\n",
    "    return x ** 2 * w2 + x * w1 +b\n",
    "\n",
    "# Loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "# compute gradient\n",
    "def gradientb(x, y):  # d_loss/d_b\n",
    "    return 2 * (b - y + w2 * x **2 + w1 * x)\n",
    "\n",
    "# compute gradient\n",
    "def gradientw1(x, y):  # d_loss/d_w1\n",
    "    return 2 * x * (x * w1 - y + w2 * x ** 2 + b)\n",
    "\n",
    "# compute gradient\n",
    "def gradientw2(x, y):  # d_loss/d_w2\n",
    "    return 2 * x ** 2 * (x ** 2 * w2 - y + w1 * x + b)\n",
    "\n",
    "\n",
    "# Before training\n",
    "print(\"predict (before training)\",  4, forward(4))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    gradbsum = 0\n",
    "    gradw1sum = 0\n",
    "    gradw2sum = 0\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        gradb = gradientb(x_val, y_val)\n",
    "        gradw1 = gradientw1(x_val, y_val)\n",
    "        gradw2 = gradientw2(x_val, y_val)\n",
    "        gradbsum += gradb\n",
    "        gradw1sum += gradw1\n",
    "        gradw2sum += gradw2\n",
    "    b = b - 0.01 * gradbsum/len(x_data)\n",
    "    w1 = w1 - 0.01 * gradw1sum/len(x_data)\n",
    "    w2 = w2 - 0.01 * gradw2sum/len(x_data)\n",
    "    print(\"\\tw,y: \", x_val, y_val)\n",
    "    print(\"\\tgradw1: \",gradw1)\n",
    "    print(\"\\tgradw2: \",gradw2)\n",
    "    print(\"\\tgradb: \", gradb)\n",
    "    l = loss(x_val, y_val)\n",
    "\n",
    "    print(\"progress:\", epoch, \"w1,w2=\", w1,w2, \"loss=\", l)\n",
    "\n",
    "# After training\n",
    "print(\"predict (after training)\",  \"Some epochs\", forward(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
